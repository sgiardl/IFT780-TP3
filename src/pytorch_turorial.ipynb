{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutoriel pytorch - TP3 - IFT725\n",
    "\n",
    "Tel que mentionné dans l'énoncé du travail, vous devez recopier les blocs de code du tutoriel suivant\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "\n",
    "en donnant, pour chaque bloc, une description en format \"markdown\" de son contenu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm-up: numpy\n",
    "## Fonctionnement global du code\n",
    "\n",
    "#### Entrainement d'un modèle de régression polynomial simple de degré 3 avec mean-squared error loss. L'ensemble d'entraînement est constitué de 2000 points générés à partir de la fonction sinus. On souhaite donc que le modèle obtenu s'apparente à la vraie fonction sinus.\n",
    "# Principales variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 617.0814195480004\n",
      "199 433.53337545167534\n",
      "299 305.58409415653614\n",
      "399 216.32251899346247\n",
      "499 154.00409022158058\n",
      "599 110.46486465522841\n",
      "699 80.02489232650787\n",
      "799 58.729071451126494\n",
      "899 43.82110150295195\n",
      "999 33.37860690921214\n",
      "1099 26.05981281140599\n",
      "1199 20.927507328688797\n",
      "1299 17.326602374905775\n",
      "1399 14.798900598591423\n",
      "1499 13.023713230576085\n",
      "1599 11.776455251052333\n",
      "1699 10.899753206008963\n",
      "1799 10.28326940111743\n",
      "1899 9.849602858156999\n",
      "1999 9.544430067571604\n",
      "Result: y = 0.027593996445003145 + 0.8500298987346263 x + -0.004760423552845845 x^2 + -0.09237581564777107 x^3\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Create random input and output data\n",
    "x = np.linspace(-math.pi, math.pi, 2000)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Randomly initialize weights\n",
    "a = np.random.randn()\n",
    "b = np.random.randn()\n",
    "c = np.random.randn()\n",
    "d = np.random.randn()\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y\n",
    "    # y = a + b x + c x^2 + d x^3\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "print(f'Result: y = {a} + {b} x + {c} x^2 + {d} x^3')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PyTorch: Tensors\n",
    "## Fonctionnement global du code\n",
    "\n",
    "#### Entrainement d'un modèle de régression polynomial simple de degré 3 avec mean-squared error loss comme à l'étape précédente. Toutefois, ici les données et les poids du modèles sont plutôt conservés dans des tenseurs PyTorch.\n",
    "\n",
    "# Principales variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 3518.184326171875\n",
      "199 2473.533203125\n",
      "299 1740.6171875\n",
      "399 1226.155517578125\n",
      "499 864.86474609375\n",
      "599 611.02734375\n",
      "699 432.609375\n",
      "799 307.15240478515625\n",
      "899 218.901611328125\n",
      "999 156.80075073242188\n",
      "1099 113.08637237548828\n",
      "1199 82.30486297607422\n",
      "1299 60.62335205078125\n",
      "1399 45.347373962402344\n",
      "1499 34.58151626586914\n",
      "1599 26.99226188659668\n",
      "1699 21.641061782836914\n",
      "1799 17.867067337036133\n",
      "1899 15.20484447479248\n",
      "1999 13.326509475708008\n",
      "Result: y = 0.06984129548072815 + 0.8446105718612671 x + -0.012048786506056786 x^2 + -0.09160496294498444 x^3\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Randomly initialize weights\n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}